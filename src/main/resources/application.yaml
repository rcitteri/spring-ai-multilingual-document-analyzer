spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/mydb
    username: myuser
    password: mypassword
    driver-class-name: org.postgresql.Driver
  jpa:
    hibernate:
      ddl-auto: update
  application:
    name: pdf-analyzer
  servlet:
    multipart:
      enabled: true
      max-file-size: 50MB
      max-request-size: 50MB
  http:
    multipart:
      enabled: true
      max-file-size: 50MB
      max-request-size: 50MB
  ai:
    model:
      embedding: ollama
      chat: ollama
    ollama:
      init:
        pull-model-strategy: when_missing
      embedding:
        additional-models:
          - nomic-embed-text:latest
        options:
          model: nomic-embed-text:latest
      chat:
        additional-models:
          - gpt-oss:20b
        options:
          model: gpt-oss:20b
          num-ctx: 131027
          temperature: 0.2
    chat:
      memory:
        repository:
          jdbc:
            initialize-schema: always
      embedding:
    openai:
      api-key: ${OPENAI_API_KEY}
      embedding:
        options:
          model: text-embedding-3-small 				
    vectorstore:
      pgvector:
        initialize-schema: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        dimensions: {VECTOR_DIMENSIONS:768}
        batching-strategy: TOKEN_COUNT
        max-document-batch-size: 10000
  sql:
    init:
      mode: always
server:
  tomcat:
    max-post-size: 52428800
    max-http-header-size: 65536
    max-swallow-size: 100MB
  shutdown: immediate

logging:
  level:
    org:
      apache:
        pdfbox:
          pgmodel:
            font:
              FileSystemFontProvider: ERROR

app:
  ai:
    topk: 50  # Number of document chunks to retrieve for RAG context
    maxChatHistory: 3  # Legacy - no longer used with new token-based memory
    maxChatTokens: 12000  # Maximum tokens for chat history (with summarization)
    recentMessageCount: 6  # Number of recent messages to keep in full (not summarized)
    beChatty: "no"

    # Adaptive Semantic Chunking Configuration
    # These values are hard-coded in AdaptiveSemanticChunker but documented here for reference
    # MIN_CHUNK_SIZE: 256 tokens - Minimum size to prevent tiny chunks
    # TARGET_CHUNK_SIZE: 384 tokens - Ideal size (~3-4 paragraphs or 1 section)
    # MAX_CHUNK_SIZE: 512 tokens - Hard upper limit (safe for nomic-embed-text model)
    # OVERLAP_SIZE: 100 tokens - Context overlap between adjacent chunks
    #
    # With topK=50 and target chunk size of 384 tokens:
    # Total retrieval context: ~19,200 tokens of semantically relevant content
    # Combined with 12,000 token chat history = ~31,200 total context
    # Well within the 131,027 token context window of gpt-oss:20b

    # Standard prompt template (without Chain-of-Thought)
    # MUST include <query> and <question_answer_context> placeholders per Spring AI requirements
    promptTemplate: |
      Context information from uploaded documents:
      ---------------------
      <question_answer_context>
      ---------------------

      Question: <query>

      CITATION RULES:
      - Each context chunk above starts with [SOURCE: filename, PAGE: N]
      - For EVERY piece of information you use, cite the source
      - Use the EXACT filename and page number from the [SOURCE] tag - do NOT make them up
      - Citation format depends on the language of your answer:
        - If answering in Hebrew: (מקור: filename, עמוד N)
        - If answering in English: (Source: filename, Page N)
      - Example: If you see [SOURCE: report.pdf, PAGE: 5] and answering in English, cite as: (Source: report.pdf, Page 5)
      - Example: If you see [SOURCE: תנאי ביטוח.pdf, PAGE: 2] and answering in Hebrew, cite as: (מקור: תנאי ביטוח.pdf, עמוד 2)

      Other Instructions:
      - Answer using ONLY the context above
      - Be direct and natural in your response
      - If the context doesn't contain the answer, say you don't have that information
      - Answer in the same language as the question


    # Chain-of-Thought prompt template (when enabled by user)
    # MUST include <query> and <question_answer_context> placeholders per Spring AI requirements
    promptTemplateWithCoT: |
      Context information from uploaded documents:
      ---------------------
      <question_answer_context>
      ---------------------

      Question: <query>

      Before answering, assess the information:
      **THINKING:** Briefly identify what specific facts/numbers in the context answer the question.
      **CONFIDENCE:** [HIGH/MEDIUM/LOW/NONE]

      **ANSWER:**
      Provide a SPECIFIC answer with exact details (numbers, amounts, names) from the context.
      Do NOT give generic explanations - extract and cite the specific information.

      CITATION RULES:
      - Each context chunk starts with [SOURCE: filename, PAGE: N]
      - Cite every fact: (מקור: filename, עמוד N) for Hebrew, (Source: filename, Page N) for English
      - Extract the EXACT page number from each chunk's [SOURCE] tag

      Answer in the same language as the question.

    systemText: |
      You are a helpful AI assistant for a document question-answering system.

      IMPORTANT: Documents have already been uploaded and indexed. When a user asks a question,
      relevant excerpts from these documents are automatically retrieved and provided to you
      in the context section below. You do NOT need the user to upload files - they are already available.

      Your role:
      1. Read the context information provided between the dashed lines
      2. Use this context to answer the user's questions about the documents
      3. Answer directly and naturally - do not say "Based on the context..." or ask for files
      4. Always cite your sources using the format: (Source: filename.pdf, page X)
      5. Only say you cannot answer if the provided context is truly empty or irrelevant
      6. Never make up information that is not in the provided context

      Language:
      - If asked in Hebrew, respond in Hebrew
      - If asked in English, respond in English

